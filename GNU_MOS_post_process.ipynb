{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import argparse\n",
    "import importlib\n",
    "\n",
    "from utils.transforms import Crop\n",
    "from datasets.utils import relabel, parse_calibration, parse_poses, Trans\n",
    "from utils.metric import MultiClassMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Ï†ÑÏó≠ ÏÑ§Ï†ï\n",
    "RANGE_X = (-50.0, 50.0)\n",
    "RANGE_Y = (-50.0, 50.0)\n",
    "SIZE_XY = (512, 512)  # (H, W)\n",
    "FRAMES_MAX = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Îç∞Ïù¥ÌÑ∞ Î°úÎìú & Ï¥àÍ∏∞Ìôî\n",
    "def get_data(data_path, pred_path, fname, task_cfg):\n",
    "    pts = np.fromfile(os.path.join(data_path, fname), dtype=np.float32).reshape(-1, 4)\n",
    "    lbl_raw = np.fromfile(os.path.join(pred_path, fname.split(\".\")[0] + \".label\"), dtype=np.uint32)\n",
    "    sem16 = lbl_raw & 0xFFFF\n",
    "    sem = relabel(sem16, task_cfg[\"learning_map\"])\n",
    "    return pts, sem\n",
    "\n",
    "\n",
    "# üîπ BEV Í≤©Ïûê Ï¢åÌëú Í≥ÑÏÇ∞\n",
    "def QuantizeBEV(pcds, range_x=RANGE_X, range_y=RANGE_Y, size_xy=SIZE_XY):\n",
    "    x, y = pcds[:, 0], pcds[:, 1]\n",
    "    dx = (range_x[1] - range_x[0]) / size_xy[0]\n",
    "    dy = (range_y[1] - range_y[0]) / size_xy[1]\n",
    "    xi = ((x - range_x[0]) / dx).astype(np.int32)\n",
    "    yi = ((y - range_y[0]) / dy).astype(np.int32)\n",
    "    return np.stack([xi, yi], axis=-1)  # (N,2)\n",
    "\n",
    "\n",
    "# üîπ 2D Í≤©Ïûê Ìà¨Ìëú\n",
    "def determine_voxel_labels_bev(xy, sem_lbl, size_xy=SIZE_XY):\n",
    "    H, W = size_xy\n",
    "    C = int(sem_lbl.max().item()) + 1\n",
    "    valid = (xy[:, 0] >= 0) & (xy[:, 0] < H) & (xy[:, 1] >= 0) & (xy[:, 1] < W)\n",
    "    coords = xy[valid]\n",
    "    labels = sem_lbl[valid]\n",
    "    votes = torch.zeros(H * W, C, device=labels.device, dtype=torch.long)\n",
    "    idx1d = coords[:, 0] * W + coords[:, 1]\n",
    "    votes.scatter_add_(0, idx1d.unsqueeze(1).expand(-1, C), F.one_hot(labels, C).to(votes.dtype))\n",
    "    grid2d = votes.view(H, W, C).argmax(dim=-1)\n",
    "    return grid2d  # (H,W)\n",
    "\n",
    "\n",
    "# üîπ Ìè¨Ïù∏Ìä∏ ÎùºÎ≤® Ïó≠Îß§Ìïë\n",
    "def get_point_labels_from_voxel_labels_bev(xy, grid2d):\n",
    "    H, W = grid2d.shape\n",
    "    N = xy.shape[0]\n",
    "    out = torch.zeros(N, device=grid2d.device, dtype=torch.long)\n",
    "    valid = (xy[:, 0] >= 0) & (xy[:, 0] < H) & (xy[:, 1] >= 0) & (xy[:, 1] < W)\n",
    "    coords = xy[valid]\n",
    "    out[valid] = grid2d[coords[:, 0], coords[:, 1]]\n",
    "    return out  # (N,)\n",
    "\n",
    "\n",
    "# üîπ DBSCAN + 2D ConvexHull Í∏∞Î∞ò Ïû¨Î∂ÑÎ•ò\n",
    "def cluster_bev(pts_xy, labels, eps=0.5, min_samples=5):\n",
    "    idx_fg = (labels == 2).nonzero(as_tuple=False).squeeze()\n",
    "    if idx_fg.numel() == 0:\n",
    "        return labels\n",
    "    pts = pts_xy[idx_fg].cpu().numpy()\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(pts)\n",
    "    for cl in set(db.labels_):\n",
    "        if cl < 0:\n",
    "            continue\n",
    "        m = db.labels_ == cl\n",
    "        hull = ConvexHull(pts[m])\n",
    "        dela = Delaunay(pts[m][hull.vertices])\n",
    "        all_pts = pts_xy.cpu().numpy()\n",
    "        in_h = dela.find_simplex(all_pts) >= 0\n",
    "        stat = int((labels[in_h] == 1).sum().item())\n",
    "        mov = int((labels[in_h] == 2).sum().item())\n",
    "        new_lbl = 2 if mov > stat else 1\n",
    "        affected = idx_fg[m]\n",
    "        labels[affected] = new_lbl\n",
    "    return labels\n",
    "\n",
    "\n",
    "# üîπ ÌîÑÎ†àÏûÑ Îã®ÏúÑ ÌõÑÏ≤òÎ¶¨ (BEV)\n",
    "def post_processing_bev(idx):\n",
    "    global files, data_path, pred_path, pred_bf_path, poses, save_path, crop_fov, task_cfg\n",
    "\n",
    "    # 1) ÌòÑÏû¨ ÌîÑÎ†àÏûÑ Î°úÎìú\n",
    "    pts_c, lbl_c = get_data(data_path, pred_path, files[idx], task_cfg)\n",
    "    raw_bf = np.fromfile(os.path.join(pred_bf_path, files[idx].split(\".\")[0] + \".label\"), dtype=np.uint32)\n",
    "    lbl_bf = relabel(raw_bf & 0xFFFF, task_cfg[\"learning_map\"])\n",
    "\n",
    "    # 2) Í≥ºÍ±∞ ÌîÑÎ†àÏûÑ ÌÜµÌï©\n",
    "    inv_cur = np.linalg.inv(poses[idx])\n",
    "    hist_pts, hist_lbl = [], []\n",
    "    if idx >= FRAMES_MAX:\n",
    "        ids = range(idx - FRAMES_MAX, idx)\n",
    "    else:\n",
    "        ids = [i for i in range(FRAMES_MAX) if i != idx]\n",
    "    for h in ids:\n",
    "        p, l = get_data(data_path, pred_path, files[h], task_cfg)\n",
    "        mat = inv_cur.dot(poses[h])\n",
    "        p = Trans(p, mat)\n",
    "        hist_pts.append(p)\n",
    "        hist_lbl.append(l)\n",
    "    h_pts = np.concatenate(hist_pts, axis=0)\n",
    "    h_lbl = np.concatenate(hist_lbl, axis=0)\n",
    "\n",
    "    # 3) FOV ÌÅ¨Î°≠\n",
    "    h_pts, h_lbl, _ = crop_fov(h_pts, h_lbl)\n",
    "    pts_o, lbl_o = pts_c.copy(), lbl_c.copy()\n",
    "    pts_c, lbl_c, mask = crop_fov(pts_c, lbl_c)\n",
    "\n",
    "    # 4) BEV Ìà¨Ìëú\n",
    "    all_pts = np.vstack([h_pts[:, :3], pts_c[:, :3]])\n",
    "    all_lbl = np.concatenate([h_lbl, lbl_c])\n",
    "    bev_xy = QuantizeBEV(all_pts)\n",
    "    bev_xy_t = torch.tensor(bev_xy, device=\"cuda\").long()\n",
    "    sem_t = torch.tensor(all_lbl, device=\"cuda\").long()\n",
    "    grid2d = determine_voxel_labels_bev(bev_xy_t, sem_t)\n",
    "    curr_xy = bev_xy_t[h_pts.shape[0] :]\n",
    "    new_lbl = get_point_labels_from_voxel_labels_bev(curr_xy, grid2d)\n",
    "    lbl_o[mask] = new_lbl.cpu().numpy()\n",
    "\n",
    "    # 5) ÌÅ¥Îü¨Ïä§ÌÑ∞ Ïû¨ÌåêÏ†ï\n",
    "    pts_xy_t = torch.tensor(pts_o[:, :2], device=\"cuda\")\n",
    "    lbl_t = torch.tensor(lbl_o, device=\"cuda\").long()\n",
    "    refined = cluster_bev(pts_xy_t, lbl_t)\n",
    "    lbl_o = refined.cpu().numpy()\n",
    "\n",
    "    # 6) Ï†ÄÏû•\n",
    "    out = relabel(lbl_o, task_cfg[\"learning_map_inv\"])\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    out.tofile(os.path.join(save_path, files[idx].split(\".\")[0] + \".label\"))\n",
    "\n",
    "\n",
    "# üîπ ÌèâÍ∞Ä ÏßÄÌëú Í≥ÑÏÇ∞\n",
    "def metric_bev(root_seq, save_seq):\n",
    "    val_path = os.path.join(save_seq, \"predictions/\")\n",
    "    gt_path = os.path.join(root_seq, \"08/labels/\")\n",
    "    flist = sorted(os.listdir(gt_path))\n",
    "    with open(\"datasets/semantic-kitti.yaml\", \"r\") as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    crit = MultiClassMetric([\"static\", \"moving\"])\n",
    "    for fn in tqdm(flist):\n",
    "        g = np.fromfile(os.path.join(gt_path, fn), dtype=np.uint32) & 0xFFFF\n",
    "        gt = torch.tensor(relabel(g, cfg[\"learning_map\"]), device=\"cuda\")\n",
    "        p = np.fromfile(os.path.join(val_path, fn), dtype=np.uint32) & 0xFFFF\n",
    "        pr = torch.tensor(relabel(p, cfg[\"learning_map\"]), device=\"cuda\").long()\n",
    "        crit.addBatch(gt, F.one_hot(pr, num_classes=2))\n",
    "    print(\"BEV Best Epoch ‚Üí\", crit.get_metric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Î©îÏù∏\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", type=str, required=True)\n",
    "    parser.add_argument(\"--tag\",    type=str, default=\"bev\")\n",
    "    parser.add_argument(\"--modal\",  type=str, default=\"val\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    cfg_mod = importlib.import_module(args.config.replace(\".py\",\"\").replace(\"/\",\".\"))\n",
    "    pGen,_,_,_ = cfg_mod.get_config()\n",
    "    prefix = pGen.name\n",
    "\n",
    "    # Îç∞Ïù¥ÌÑ∞ÏÖã ÏÑ§Ï†ï\n",
    "    with open(\"datasets/semantic-kitti.yaml\",\"r\") as f:\n",
    "        task_cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "    base = \"/home/workspace/KITTI/dataset/sequences\"\n",
    "    if args.modal==\"val\":\n",
    "        seqs = [\"08\"]\n",
    "        pred_root    = f\"experiments/{prefix}/{args.tag}/val_results/sequences\"\n",
    "        pred_bf_root = f\"experiments/{prefix}/{args.tag}/val_bf_results/sequences\"\n",
    "        save_root    = f\"experiments/{prefix}/{args.tag}/bev_refine_val/sequences\"\n",
    "    else:\n",
    "        seqs = [str(i) for i in range(11,22)]\n",
    "        pred_root    = f\"experiments/{prefix}/{args.tag}/test_results/sequences\"\n",
    "        pred_bf_root = f\"experiments/{prefix}/{args.tag}/test_bf_results/sequences\"\n",
    "        save_root    = f\"experiments/{prefix}/{args.tag}/bev_refine_test/sequences\"\n",
    "\n",
    "    crop_fov = Crop(dims=(0,1,2), fov=[[-50,-50,-4],[50,50,2]])\n",
    "\n",
    "    for seq in seqs:\n",
    "        print(f\"‚ñ∂ Sequence {seq}\")\n",
    "        data_path    = os.path.join(base, seq, \"velodyne/\")\n",
    "        calib_path   = os.path.join(base, seq, \"calib.txt\")\n",
    "        pose_path    = os.path.join(base, seq, \"poses.txt\")\n",
    "        pred_path    = os.path.join(pred_root,    seq, \"predictions/\")\n",
    "        pred_bf_path = os.path.join(pred_bf_root, seq, \"predictions/\")\n",
    "        save_path    = os.path.join(save_root,    seq, \"predictions/\")\n",
    "\n",
    "        files = sorted(os.listdir(data_path))\n",
    "        poses = parse_poses(pose_path, parse_calibration(calib_path))\n",
    "\n",
    "        with Pool(8) as p:\n",
    "            list(tqdm(p.imap(post_processing_bev, range(len(files))),\n",
    "                      total=len(files)))\n",
    "        if args.modal==\"val\":\n",
    "            metric_bev(os.path.join(base, seq), save_root)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
